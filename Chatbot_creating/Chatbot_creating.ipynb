{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание чат-бота"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном мини-проекте я попробую создать чат-бота с нуля.\n",
    "\n",
    "Бот в телеграме: @anLaPark_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT_CONFIG = {\n",
    "    'intents': {\n",
    "        'hello': {\n",
    "            'examples': ['Привет','Добрый день','Привет, бот', 'нихао'],\n",
    "            'responses': ['Привет, человек','И вам здравствуйте', 'Доброго времени суток']\n",
    "        },\n",
    "        \n",
    "        'bye': {\n",
    "             'examples': ['Пока', 'До свидания', 'Досвидания', 'До скорой встречи'],\n",
    "            'responses': ['Еще увидимся', 'Если что, я всегда тут']\n",
    "        },\n",
    "        \n",
    "        'name': {\n",
    "             'examples': ['Как тебя зовут?', 'Представься', 'У тебя есть имя?'],\n",
    "            'responses': ['Меня зовут Юки']\n",
    "        },\n",
    "    },\n",
    "   \n",
    "    'failure_phrases': [\n",
    "        'Непонятно. Перефразируйте, пожалуйста',\n",
    "        'Я еще только учусь. Спросите что-нибудь другое',\n",
    "        'Слишком сложный вопрос для меня'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#разделение выборки на интенты и классы\n",
    "X_text = []\n",
    "y = []\n",
    " \n",
    "for intent, intent_data in BOT_CONFIG['intents'].items():\n",
    "    for example in intent_data['examples']:\n",
    "        X_text.append(example)\n",
    "        y.append(intent)\n",
    "        \n",
    "# векторизация\n",
    "vectorizer = TfidfVectorizer(analyzer = 'char', ngram_range = (3,3))\n",
    "\n",
    "#на этом шаге планирую использовать нейронную сеть Bert для того, чтобы получить эмбеддинги и передать их уже в SVM \n",
    "#пример у моем проекте \"BERT\" на гитхабе\n",
    "#или использовать только нейронную сеть без SVM\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "\n",
    "# ML\n",
    "clf = LinearSVC()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистка текста от лишних символов и знаков препинания\n",
    "def clean(text):\n",
    "    clean_text = ''\n",
    "    for ch in text.lower():\n",
    "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя ':\n",
    "            clean_text += ch\n",
    "    # с помощью .strip() уберем лишние пробелы в начале и в конце фразы\n",
    "    return clean_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_intent(replica):\n",
    "    replica = clean(replica)\n",
    "    intent = clf.predict(vectorizer.transform([replica]))[0]\n",
    "    \n",
    "    for example in BOT_CONFIG['intents'][intent]['examples']:\n",
    "        for example in intent_data['examples']:\n",
    "            example = clean(example)\n",
    "            #научимся работать с мелкими ошибками с помощью расстояния Левенштейна\n",
    "            distance = nltk.edit_distance(replica, example)\n",
    "            if distance / len(example) <= 0.5:\n",
    "                return intent\n",
    "classify_intent('как тебя зовут?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Мальчик, Точно.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_answer_by_intent(intent):\n",
    "      for intent in BOT_CONFIG['intents']:\n",
    "            responses = BOT_CONFIG['intents'][intent]['responses']\n",
    "            return random.choice(responses)\n",
    "        \n",
    "# в качестве корпуса текстов возьмем корпус из \n",
    "# https://github.com/Koziev/NLP_Datasets/blob/master/Conversations/Data/dialogues.zip\n",
    "\n",
    "with open('C:/Users/Anna/Desktop/dialogues.txt', encoding=\"utf8\") as f:\n",
    "    content = f.read()\n",
    "    \n",
    "content[:1000]\n",
    "\n",
    "# запишем каждый диалог с новой строки и отделим фразы \\n\\n\n",
    "dialogues_str = content.split('\\n\\n')\n",
    "# уберем лишнюю \\n, оставим в диалоге только 2 фразы и выведем результат\n",
    "dialogues = [dialogues_str.split('\\n')[:2] for dialogues_str in dialogues_str]\n",
    "\n",
    "dialogues_filtered = []\n",
    "\n",
    "# убрали дубликаты диалогов\n",
    "questions = set()\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    if len(dialogue) != 2:\n",
    "        continue\n",
    "    \n",
    "    question, answer = dialogue\n",
    "    #убираем перевые два символа из фразы\n",
    "    question = clean(question[2:])\n",
    "    answer = answer[2:]\n",
    "    \n",
    "    if question != '' and question not in questions:\n",
    "        questions.add(question)\n",
    "        dialogues_filtered.append([question, answer])\n",
    "\n",
    "# структурируем вопросы по словам для повышения скорости вычислений\n",
    "dialogues_structured = {}\n",
    "\n",
    "for question, answer in dialogues_filtered:\n",
    "    words = question.split(' ')\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in dialogues_structured:\n",
    "            dialogues_structured[word] = []\n",
    "        dialogues_structured[word].append([question, answer])\n",
    "\n",
    "# # у слишком частотных слов оставим только первую 1000 -> на каждую пару теперь приходится не более 1000 элементов\n",
    "dialogues_structured_cut = {}\n",
    "\n",
    "for word, pairs in dialogues_structured.items():\n",
    "    pairs.sort(key=lambda pair: len(pair[0]))\n",
    "    dialogues_structured_cut[word] = pairs[:1000]\n",
    "    \n",
    "# генерируем ответ    \n",
    "def generate_answer(replica):\n",
    "    \n",
    "    replica = clean(replica)\n",
    "    words = set(replica.split(' '))\n",
    "    \n",
    "    mini_dataset = []\n",
    "    for word in words:\n",
    "        if word in dialogues_structured:\n",
    "            mini_dataset += dialogues_structured_cut[word]     \n",
    "    \n",
    "    print(len(mini_dataset))\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    for question, answer in mini_dataset:\n",
    "        # чтобы не считать расстоянение заведомо далеких фраз, отфильтруем их\n",
    "        abs(len(replica) - len(question)) < 0.2\n",
    "        #научимся работать с мелкими ошибками с помощью расстояния Левинштейна\n",
    "        distance = nltk.edit_distance(replica, question)\n",
    "        distance_weighted = distance / len(question)\n",
    "        if distance_weighted < 0.2:\n",
    "            answers.append([distance_weighted, question, answer])\n",
    "            \n",
    "        # из всех подходящих вариантов выберем не первый, а наиболее близкий по distance \n",
    "    if answers:\n",
    "        return min(answers, key=lambda three: three[0])[2]\n",
    "    \n",
    "#зададим вопрос боту            \n",
    "generate_answer('мальчик или девочка?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failure_phrase():\n",
    "    failure_phrases = [\n",
    "      \"Слишком ложно и непонятно, напиши чутка иначе\",\n",
    "      \"Я понял, что я не понял\",\n",
    "      \"что-то непонятно\",\n",
    "      \"Краткость - сестра таланта, скажите короче\",\n",
    "      \"Давай еще разочек\",\n",
    "      \"Пожалуйста, уточните\",\n",
    "      \"Не могли бы вы уточнить вопрос?\",\n",
    "    ]\n",
    "    return random.choice(failure_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим статистику пути выбора ответа\n",
    "stats = {'intent': 0, 'generate': 0, 'failure': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot(replica):\n",
    "    # NLU\n",
    "    intent = classify_intent(replica)\n",
    "    \n",
    "    # answer generation\n",
    "   \n",
    "    #выбор заготовленной реплики - ML\n",
    "    if intent:\n",
    "            answer = get_answer_by_intent(intent)\n",
    "            if answer:\n",
    "                stats['intent'] += 1\n",
    "                return answer\n",
    "    \n",
    "    # вызов генеративной модели\n",
    "    answer = generate_answer(replica)\n",
    "    if answer:\n",
    "        stats['generate'] += 1\n",
    "        return answer\n",
    "    \n",
    "    # берем заглушку\n",
    "    stats['failure'] += 1\n",
    "    return get_failure_phrase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'что-то непонятно'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot('первый закон термодинамики')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 0, 'generate': 0, 'failure': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: python-telegram-bot in c:\\users\\anna\\anaconda3\\lib\\site-packages (13.5)\n",
      "Requirement already satisfied, skipping upgrade: certifi in c:\\users\\anna\\anaconda3\\lib\\site-packages (from python-telegram-bot) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: APScheduler==3.6.3 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from python-telegram-bot) (3.6.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2018.6 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from python-telegram-bot) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5.1 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from python-telegram-bot) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: tzlocal>=1.2 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from APScheduler==3.6.3->python-telegram-bot) (2.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.4.0 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=0.7 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from APScheduler==3.6.3->python-telegram-bot) (50.3.1.post20201107)\n"
     ]
    }
   ],
   "source": [
    "# приступаем к настройке бота из https://github.com/python-telegram-bot/python-telegram-bot\n",
    "!pip install python-telegram-bot --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telegram import Update, ForceReply\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "\n",
    "def start(update: Update, _: CallbackContext) -> None:\n",
    "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
    "    user = update.effective_user\n",
    "    update.message.reply_markdown_v2(\n",
    "        fr'Hi {user.mention_markdown_v2()}\\!',\n",
    "        reply_markup=ForceReply(selective=True),\n",
    "    )\n",
    "\n",
    "\n",
    "def help_command(update: Update, _: CallbackContext) -> None:\n",
    "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
    "    update.message.reply_text('Help!')\n",
    "\n",
    "\n",
    "def run_bot(update: Update, _: CallbackContext) -> None:\n",
    "    \"\"\"Echo the user message.\"\"\"\n",
    "    replica = update.message.text\n",
    "    answer = bot(replica)\n",
    "    update.message.reply_text(answer)\n",
    "\n",
    "    print(stats)\n",
    "    print(replica)\n",
    "    print(answer)\n",
    "    print()\n",
    "    \n",
    "def main() -> None:\n",
    "    \"\"\"Start the bot.\"\"\"\n",
    "    updater = Updater(\"1851878749:AAHTjneIuKGYGJ8vOXdmQujMVFBLZpTsmZg\")\n",
    "    dispatcher = updater.dispatcher\n",
    "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
    "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\n",
    "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, run_bot))\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'intent': 0, 'generate': 1, 'failure': 1}\n",
      "привет!\n",
      "Привет!\n",
      "\n",
      "2000\n",
      "{'intent': 0, 'generate': 2, 'failure': 1}\n",
      "как дела?\n",
      "Нормально, А почему не гуляем на свадьбе?\n",
      "\n",
      "2000\n",
      "{'intent': 0, 'generate': 3, 'failure': 1}\n",
      "не знаю\n",
      "Не знаешь и летишь?\n",
      "\n",
      "2000\n",
      "{'intent': 0, 'generate': 4, 'failure': 1}\n",
      "кто ты?\n",
      "Беннат я.\n",
      "\n",
      "{'intent': 1, 'generate': 4, 'failure': 1}\n",
      "как тебя зовут?\n",
      "И вам здравствуйте\n",
      "\n",
      "1015\n",
      "{'intent': 1, 'generate': 4, 'failure': 2}\n",
      "закажи мне роллы\n",
      "Давай еще разочек\n",
      "\n",
      "43\n",
      "{'intent': 1, 'generate': 4, 'failure': 3}\n",
      "закажи пиццу\n",
      "Пожалуйста, уточните\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Справка: Подбор модели, параметров и валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "scores = []\n",
    "\n",
    "#vectorizer = CountVectorizer(analyzer = 'char', ngram_range = (3,3))\n",
    "vectorizer = TfidfVectorizer(analyzer = 'char', ngram_range = (3,3))\n",
    "\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(scores)\n",
    "print(sum(scores) / len(scores))\n",
    "\n",
    "#проверим, какого максимального качества может добиться логистическая модель\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
